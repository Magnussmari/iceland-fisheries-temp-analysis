"""
NetCDF Data Explorer - Copernicus Ocean Data
Explores meteorological and oceanographic data from NetCDF files
"""

import xarray as xr
import pandas as pd
import numpy as np
from pathlib import Path
import sys

def explore_netcdf(file_path):
    """
    Explore a NetCDF file and print comprehensive information
    """
    print("=" * 80)
    print(f"NETCDF GAGNAK√ñNNUN")
    print("=" * 80)
    print(f"Skr√°: {Path(file_path).name}")
    print(f"Sl√≥√∞: {file_path}")
    print()

    try:
        # Open dataset
        ds = xr.open_dataset(file_path)

        print("üìä GRUNNT√ñLFR√Ü√êI")
        print("-" * 80)
        print(f"Gagnasni√∞: NetCDF")
        print(f"Fj√∂ldi breyta: {len(ds.data_vars)}")
        print(f"Fj√∂ldi v√≠dda: {len(ds.dims)}")
        print(f"Fj√∂ldi eiginda: {len(ds.attrs)}")
        print()

        # Dimensions
        print("üìê V√çDDIR (DIMENSIONS)")
        print("-" * 80)
        for dim, size in ds.dims.items():
            print(f"  {dim:20s} : {size:,} gildi")
        print()

        # Coordinates
        print("üìç HNIT (COORDINATES)")
        print("-" * 80)
        for coord_name, coord_var in ds.coords.items():
            coord_info = f"  {coord_name:20s} : {coord_var.dims}"
            if coord_var.size > 0:
                try:
                    if np.issubdtype(coord_var.dtype, np.datetime64):
                        first_val = pd.Timestamp(coord_var.values[0])
                        last_val = pd.Timestamp(coord_var.values[-1])
                        coord_info += f" [{first_val} til {last_val}]"
                    else:
                        first_val = float(coord_var.values[0])
                        last_val = float(coord_var.values[-1])
                        coord_info += f" [{first_val:.4f} til {last_val:.4f}]"
                except:
                    pass
            print(coord_info)
        print()

        # Variables
        print("üî¢ BREYTUR (VARIABLES)")
        print("-" * 80)
        for var_name, var in ds.data_vars.items():
            print(f"\n  {var_name}")
            print(f"    V√≠ddir: {var.dims}")
            print(f"    St√¶r√∞: {var.shape}")
            print(f"    Ger√∞: {var.dtype}")

            # Get attributes
            if hasattr(var, 'long_name'):
                print(f"    Nafn: {var.long_name}")
            if hasattr(var, 'units'):
                print(f"    Eining: {var.units}")
            if hasattr(var, 'standard_name'):
                print(f"    Sta√∞la√∞ nafn: {var.standard_name}")

            # Basic statistics for numeric data
            if np.issubdtype(var.dtype, np.number):
                try:
                    values = var.values
                    valid_values = values[~np.isnan(values)]
                    if len(valid_values) > 0:
                        print(f"    T√∂lfr√¶√∞i:")
                        print(f"      L√°gmark:   {np.nanmin(values):.4f}")
                        print(f"      H√°mark:    {np.nanmax(values):.4f}")
                        print(f"      Me√∞altal:  {np.nanmean(values):.4f}")
                        print(f"      Mi√∞gildi:  {np.nanmedian(values):.4f}")
                        print(f"      Std.fr√°v.: {np.nanstd(values):.4f}")
                        print(f"      Fj√∂ldi gilt gildi: {len(valid_values):,}")
                        print(f"      Fj√∂ldi NaN: {np.isnan(values).sum():,}")
                except Exception as e:
                    print(f"      (Villa vi√∞ √∫treikning t√∂lfr√¶√∞i: {e})")
        print()

        # Global attributes
        print("üè∑Ô∏è  EIGINDI (GLOBAL ATTRIBUTES)")
        print("-" * 80)
        for attr_name, attr_value in ds.attrs.items():
            attr_str = str(attr_value)
            if len(attr_str) > 70:
                attr_str = attr_str[:67] + "..."
            print(f"  {attr_name:30s} : {attr_str}")
        print()

        # Memory usage
        print("üíæ MINNISNOTKUN")
        print("-" * 80)
        total_bytes = sum(var.nbytes for var in ds.data_vars.values())
        print(f"  Heildarminnisnotkun: {total_bytes / 1024**2:.2f} MB")
        for var_name, var in ds.data_vars.items():
            print(f"    {var_name:20s} : {var.nbytes / 1024**2:.2f} MB")
        print()

        # Suggest potential analyses
        print("üí° M√ñGULEGAR GREININGAR")
        print("-" * 80)

        # Check for time dimension
        time_dims = [d for d in ds.dims if 'time' in d.lower()]
        if time_dims:
            print(f"  ‚úì T√≠mara√∞agreining (time dimension: {time_dims[0]})")

        # Check for spatial dimensions
        spatial_dims = []
        for d in ds.dims:
            if any(x in d.lower() for x in ['lat', 'lon', 'x', 'y']):
                spatial_dims.append(d)
        if len(spatial_dims) >= 2:
            print(f"  ‚úì Landfr√¶√∞ileg kortlagning (dimensions: {', '.join(spatial_dims)})")

        # Check for depth/level
        depth_dims = [d for d in ds.dims if any(x in d.lower() for x in ['depth', 'level', 'z'])]
        if depth_dims:
            print(f"  ‚úì D√Ωptar/h√¶√∞argreining (dimension: {depth_dims[0]})")

        print("  ‚úì T√∂lfr√¶√∞ileg samantekt")
        print("  ‚úì Dreifirit (histograms)")
        print("  ‚úì Fylgnifylki milli breyta")

        print()
        print("=" * 80)
        print("‚úì K√ñNNUN LOKI√ê")
        print("=" * 80)

        return ds

    except Exception as e:
        print(f"‚ùå VILLA: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_to_csv(ds, output_path, variables=None, flatten_time=True):
    """
    Extract data from NetCDF to CSV format
    """
    print(f"\nüìù Umbreyti √≠ CSV...")

    if variables is None:
        variables = list(ds.data_vars.keys())

    # Convert to DataFrame
    df = ds[variables].to_dataframe()

    if flatten_time:
        df = df.reset_index()

    df.to_csv(output_path, index=False)
    print(f"‚úì Vista√∞ √≠: {output_path}")
    print(f"  Fj√∂ldi ra√∞a: {len(df):,}")
    print(f"  Fj√∂ldi d√°lka: {len(df.columns)}")

    return df


if __name__ == "__main__":
    import os

    # Default file path (adjusted for scripts/02_data_fetching/)
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent

    default_file = project_root / "data/raw/Copernicus/igp_alliance_surface_met_20180207_qc3_10min.nc"

    # Check command line arguments
    if len(sys.argv) > 1:
        nc_file = Path(sys.argv[1])
    else:
        nc_file = default_file

    if not nc_file.exists():
        print(f"‚ùå Villa: Skr√° fannst ekki: {nc_file}")
        sys.exit(1)

    # Explore the file
    ds = explore_netcdf(str(nc_file))

    if ds is not None:
        # Ask if user wants to export to CSV
        print("\n" + "=" * 80)
        response = input("Viltu vista g√∂gnin sem CSV? (j/n): ").lower()

        if response in ['j', 'j√°', 'y', 'yes']:
            output_file = project_root / "data/processed/copernicus" / f"{nc_file.stem}.csv"
            output_file.parent.mkdir(parents=True, exist_ok=True)

            extract_to_csv(ds, str(output_file))

        ds.close()
